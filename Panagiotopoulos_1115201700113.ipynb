{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f294306",
      "metadata": {
        "id": "6f294306"
      },
      "source": [
        "# <div style=\"text-align:center\">3η Εργασία</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a5bb9a",
      "metadata": {
        "id": "e9a5bb9a"
      },
      "source": [
        "Στην παρούσα εργασία θα ασχοληθείτε με την πρόβλεψη μουσικού είδους από σήματα\n",
        "μουσικής με τη χρήση νευρωνικών δικτύων. Πιο συγκεκριμένα, ο στόχος της εργασία είναι\n",
        "να ταξινομήσουμε 1 δευτερόλεπτο μουσικού σήματος στα εξής είδη: κλασσική μουσική, ποπ,\n",
        "ροκ, και μπλουζ. Για κάθε 1 δευτερόλεπτο σας παρέχονται δύο ειδών αναπαραστάσεις του\n",
        "ηχητικού σήματος: (i) MFCCs, και (ii) mel-spectograms. <br><br>\n",
        "Τα MFCCs είναι συντελεστές του φάσματος ισχύος μετασχηματισμένοι με βάση την κλίμακα\n",
        "mel, μία κλίμακα που είναι κοντά στον τρόπο που αντιλαμβάνεται ο άνθρωπος τα ηχητικά\n",
        "σήματα μέσω της ακοής. Στην δική μας περίπτωση χρησιμοποιούμε 13 συντελεστές οι οποίοι\n",
        "υπολογίζονται για κάθε 50 msec και επομένως για κάθε μουσικό κομμάτι του dataset\n",
        "προκύπτει μία ακολουθία από 20 feature vectors διάστασης 13. Για να αναπαραστήσουμε\n",
        "αυτή την πληροφορία μέσω ενός στατικού διανύσματος, το οποίο είναι ευκολότερο στην\n",
        "χρήση, υπολογίζουμε για κάθε έναν από τους 13 συντελεστές την μέση τιμή και την τυπική\n",
        "του απόκλιση από την ακολουθία των 20 χρονικών στιγμών. Καταλήγουμε λοιπόν με ένα\n",
        "διάνυσμα 26 χαρακτηριστικών για κάθε μουσικό κομμάτι του dataset. <br><br>\n",
        "To φασματογράφημα (spectrogram), που είναι ο δεύτερος τρόπος αναπαράστασης που θα\n",
        "χρησιμοποιήσουμε, είναι μία δισδιάστατη αναπαράσταση που δείχνει την χρονική εξέλιξη\n",
        "του φάσματος συχνοτήτων. Εάν στο spectrogram εφαρμόσουμε την κλίμακα mel, παίρνουμε\n",
        "το mel-spectrogram ή melgram με το οποίο και θα δουλέψουμε στην παρούσα εργασία.<br><br>\n",
        "Υπολογίζοντας και αντιστρέφοντας τους άξονες χρόνου και συχνότητας, προκύπτει για κάθε\n",
        "στοιχείο του συνόλου δεδομένων ένας πίνακας 21 (χρόνος) x 128 (συχνότητα).<br><br>\n",
        "Τα δεδομένα που θα χρησιμοποιήσετε βρίσκονται εδώ και είναι χωρισμένα στα σύνολα\n",
        "training (3200 δείγματα), validation (800 δείγματα) και test (1376 δείγματα) sets, τα οποία\n",
        "θα χρησιμοποιηθούν για εκπαίδευση, εύρεση υπερπαραμέτρων και αξιολόγηση της\n",
        "ικανότητας γενίκευσης αντίστοιχα.<br><br>\n",
        "Ακολουθήστε τις οδηγίες των παρακάτω ερωτημάτων και ετοιμάστε τις απαντήσεις σας\n",
        "τρέχοντας τον κώδικά σας στο Google Colab. Το framework που θα πρέπει να χρησιμοποιηθεί\n",
        "για τον προγραμματισμό των νευρωνικών είναι υποχρεωτικά το Pytorch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e633762",
      "metadata": {
        "id": "3e633762"
      },
      "source": [
        "### <div style=\"text-align:center\"> [Ερώτημα 1: Feedforward Neural Network] </div>\n",
        "*Βήμα 1: Φόρτωση δεδομένων (mfccs)* <br><br>\n",
        "Ξεκινάμε φορτώνοντας τα mfcc δεδομένα για train, validation και test μέσω των αντίστοιχων\n",
        "numpy αρχείων X.npy και labels.npy. Στην συνέχεια μετασχηματίζουμε τα labels από strings\n",
        "(classical, blues etc) σε ακέραιους αριθμούς από 0 μέχρι 3, κρατώντας το αντίστοιχο mapping\n",
        "από τα ονόματα των κλάσεων στους ακεραίους. Τέλος φορτώνουμε τα δεδομένα μας σε 3\n",
        "Pytorch dataloaders (ένα για κάθε σύνολο δεδομένων) με batch size 16, ώστε να μπορούν\n",
        "να χρησιμοποιηθούν στα μοντέλα μας. Δώστε επίσης το όρισμα shuffle=True στους train και\n",
        "validation dataloaders.<br><br>\n",
        "*Βήμα 2: Ορισμός Νευρωνικού Δικτύου*<br><br>\n",
        "Ορίστε μία κλάση πλήρως συνδεδεμένου Νευρωνικού Δικτύου (fully connected neural\n",
        "nework) το οποίο να αποτελείται από τα 4 επίπεδα με αριθμούς νευρώνων 26, 128, 32 και 4\n",
        "αντίστοιχα, όπου 26 είναι η διάσταση της εισόδου και 4 ο αριθμός των κλάσεων που θα\n",
        "προβλεφθούν.<br><br>\n",
        "*Βήμα 3: Ορισμός διαδικασίας εκπαίδευσης*<br><br>\n",
        "Ορίστε μία συνάρτηση που θα είναι αρμόδια για την εκπαίδευση του δικτύου. Συγκεκριμένα,\n",
        "δεδομένου ενός αριθμού εποχών, ενός optimizer, ενός dataloader, μιας συνάρτησης\n",
        "κόστους και ενός νευρωνικού θα περνάει κάθε batch από το νευρωνικό, θα υπολογίζει και\n",
        "θα τυπώνει το loss και θα ενημερώνει τα βάρη, ενώ θα τερματίζει επιστρέφοντας το\n",
        "νευρωνικό δίκτυο, όταν ο αριθμός των εποχών επιτευχθεί.<br><br>\n",
        "*Βήμα 4: Ορισμός διαδικασίας αξιολόγησης*<br><br>\n",
        "Ορίστε αντίστοιχα μία συνάρτηση αξιολόγησης, η οποία θα περνάει όλα τα batches ενός\n",
        "dataloader από το μοντέλο παίρνοντας τις προβλέψεις του και χωρίς να ενημερώνει τα βάρη.\n",
        "Μέσω των προβλέψεων θα υπολογίζει και θα επιστρέφει (i) το loss, (ii) τo f1 macro averaged,\n",
        "(iii) το accuracy, και (iv) confusion matrix.<br><br>\n",
        "*Βήμα 5: Εκπαίδευση δικτύου*<br><br>\n",
        "Εκπαιδεύστε το νευρωνικό δίκτυο στο training set χρησιμοποιώντας τα εξής:\n",
        "* optimizer: `stochastic gradient descent`\n",
        "* learning rate: `0.002`\n",
        "* loss function: `cross-entropy loss`\n",
        "* αριθμός εποχών: `30`\n",
        "\n",
        "Στην συνέχεια χρησιμοποιήστε την συνάρτηση αξιολόγησης του προηγούμενου ερωτήματος\n",
        "για να υπολογίσετε τις επιδόσεις του εκπαιδευμένου μοντέλου στο test set. Τι επιδόσεις\n",
        "πετυχαίνετε;<br><br>\n",
        "*Βήμα 6: Εκπαίδευση δικτύου με GPU*<br><br>\n",
        "Επαναλάβετε το βήμα 5, αλλά αυτή την φορά να έχετε αρχικά μεταφέρει τα δεδομένα και το\n",
        "αρχικοποιημένο νευρωνικό σας δίκτυο στην GPU του colab. Βεβαιωθείτε ότι η εκπαίδευση\n",
        "τρέχει στην GPU και τυπώστε τις διαφορές στους χρόνους εκτέλεσης σε GPU και CPU.\n",
        "Βεβαιωθείτε ότι το colab session σας περιλαμβάνει χρήση GPU - η οποία είναι δωρεάν.<br><br>\n",
        "*Βήμα 7: Επιλογή μοντέλου*<br><br>\n",
        "Κατά την διάρκεια εκπαίδευσης (30 εποχές) προκύπτουν διαφορετικά στιγμιότυπα του\n",
        "νευρωνικού μας, δηλαδή μοντέλα που έχουν διαφορετικά βάρη. Κατά την διαδικασία\n",
        "βελτιστοποίησης, δεν γνωρίζουμε ποιο στιγμιότυπο του μοντέλου μας έχει την καλύτερη\n",
        "δυνατότητα γενίκευσης. Για τον λόγο αυτό θα χρησιμοποιήσουμε το validation set στο τέλος\n",
        "κάθε εποχής ώστε να αξιολογούμε τα στιγμιότυπα του μοντέλου. Αποθηκεύστε το μοντέλο\n",
        "που έχει την καλύτερη επίδοση στην μετρική f1 για το validation set και χρησιμοποιήστε το\n",
        "για να μετρήσετε την απόδοση στο test set. Σχολιάστε τα αποτελέσματα.<br><br>\n",
        "Για τα επόμενα βήματα της εργασίας θα πρέπει να εργάζεστε με τον ίδιο τρόπο\n",
        "χρησιμοποιώντας το validation set για να βρείτε το κατάλληλο στιγμιότυπο"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f4602bfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4602bfb",
        "outputId": "ce9788df-5d4e-4984-c745-d10fc589f42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e5bf3420",
      "metadata": {
        "id": "e5bf3420"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Step 1\n",
        "main_path = '/content/drive/MyDrive/Colab Notebooks/data/music_genre_data_di'\n",
        "#main_path = 'data/music_genre_data_di'\n",
        "# Loading Training Data\n",
        "x_train = np.load(main_path + '/train/mfccs/X.npy')\n",
        "y_train = np.load(main_path + '/train/mfccs/labels.npy')\n",
        "# Loading Test Data\n",
        "x_test = np.load(main_path + '/test/mfccs/X.npy')\n",
        "y_test = np.load(main_path + '/test/mfccs/labels.npy')\n",
        "# Loading Validation Data\n",
        "x_val = np.load(main_path + '/val/mfccs/X.npy')\n",
        "y_val = np.load(main_path + '/val/mfccs/labels.npy')\n",
        "# Create the dictionary matching every genre to its index in the unique values of the train array\n",
        "unique_values = np.unique(y_train)\n",
        "replacement_dict = {value: i for i, value in enumerate(unique_values)}\n",
        "# Replace the values in each of the arrays with the values from the dictionary\n",
        "for i in range(len(unique_values)):\n",
        "    y_train = np.where(y_train == unique_values[i], replacement_dict[unique_values[i]], y_train)\n",
        "    y_test = np.where(y_test == unique_values[i], replacement_dict[unique_values[i]], y_test)\n",
        "    y_val = np.where(y_val == unique_values[i], replacement_dict[unique_values[i]], y_val)\n",
        "# Replace the ints encoded as strings to plain ints\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "y_val = y_val.astype(int)\n",
        "# Create tensors from numpuarrays\n",
        "x_train = torch.from_numpy(x_train).float() # There was a type mismatch float64 instead of float32\n",
        "y_train = torch.from_numpy(y_train).long() # And another type mismatch for long instead of int\n",
        "x_test = torch.from_numpy(x_test).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "x_val = torch.from_numpy(x_val).float()\n",
        "y_val = torch.from_numpy(y_val).long()\n",
        "# Creating datasets\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "val_dataset = TensorDataset(x_val, y_val)\n",
        "# Load on dataloders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset , batch_size=16, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset,batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b81828a4",
      "metadata": {
        "id": "b81828a4"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Step 2\n",
        "# Ορίστε μία κλάση πλήρως συνδεδεμένου Νευρωνικού Δικτύου (fully connected neural nework)\n",
        "# το οποίο να αποτελείται από τα 4 επίπεδα με αριθμούς νευρώνων 26, 128, 32 και 4 αντίστοιχα,\n",
        "# όπου 26 είναι η διάσταση της εισόδου και 4 ο αριθμός των κλάσεων που θα προβλεφθούν.\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # 26 --> 128 --> 32 --> 4\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(26, 128),  # 26 --> 128\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 32),    # 128 --> 32\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 4),     # 32 --> 4\n",
        "        )\n",
        "    # Every nn.Module subclass implements the operations on input data in the forward method.\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ec190de3",
      "metadata": {
        "id": "ec190de3"
      },
      "outputs": [],
      "source": [
        "# Step 3\n",
        "# Ορίστε μία συνάρτηση που θα είναι αρμόδια για την εκπαίδευση του δικτύου.\n",
        "# Συγκεκριμένα, δεδομένου ενός αριθμού εποχών, ενός optimizer, ενός dataloader,\n",
        "# μιας συνάρτησης κόστους και ενός νευρωνικού θα περνάει κάθε batch από το νευρωνικό,\n",
        "# θα υπολογίζει και θα τυπώνει το loss και θα ενημερώνει τα βάρη,\n",
        "# ενώ θα τερματίζει επιστρέφοντας το νευρωνικό δίκτυο, όταν ο αριθμός των εποχών επιτευχθεί.\n",
        "def train_neural_network(epochs, optimizer, dataloader, cost_function, model, device):\n",
        "    for epoch in range(epochs):\n",
        "        # for every batch\n",
        "        for X, y in dataloader:\n",
        "            # if using gpu dont forget to move the data there\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            # Compute prediction and loss\n",
        "            pred = model(X)\n",
        "            loss = cost_function(pred, y)\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(\"Epoch: \",epoch,\" loss is \", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "324eaac0",
      "metadata": {
        "id": "324eaac0"
      },
      "outputs": [],
      "source": [
        "# Step 4\n",
        "# Ορίστε αντίστοιχα μία συνάρτηση αξιολόγησης,\n",
        "# η οποία θα περνάει όλα τα batches ενός dataloader από το μοντέλο παίρνοντας τις προβλέψεις του\n",
        "# και χωρίς να ενημερώνει τα βάρη. Μέσω των προβλέψεων θα υπολογίζει και θα επιστρέφει\n",
        "# (i) το loss,\n",
        "# (ii) τo f1 macro averaged,\n",
        "# (iii) το accuracy, και\n",
        "# (iv) confusion matrix.\n",
        "def evaluate_neural_network(dataloader,model,loss_function,device):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # I used my knowledge of the number of classes but maybe it should be a parameter of the function\n",
        "    true_positives = [0, 0, 0, 0]\n",
        "    false_positives = [0, 0, 0, 0]\n",
        "    false_negatives = [0, 0, 0, 0]\n",
        "    true_negatives = [0, 0, 0, 0]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X,y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "            # confusion matrix calculation\n",
        "            predictions = pred.argmax(1)\n",
        "            for i in range(len(predictions)): # for every prediction\n",
        "                if predictions[i] == y[i]: # if the prediction is true\n",
        "                    true_positives[y[i]] += 1 # increment the true positives of this class\n",
        "                    for x in range(4): # and for every class\n",
        "                        if x != y[i]: # that it is not the predicted class\n",
        "                            true_negatives[x] += 1 # incremenet the true negatives\n",
        "                else: # else if the prediction was not correct\n",
        "                    false_positives[predictions[i]] += 1 # the increment the false positives for the predicted class\n",
        "                    false_negatives[y[i]] += 1 # increment the false negatives for the correct class\n",
        "                    for x in range(4): # and for every other class\n",
        "                        if x != y[i] and x != predictions[i]: # that is not one of the two other classes\n",
        "                            true_negatives[x] += 1 # incremenet the true negatives\n",
        "\n",
        "\n",
        "    precision = [0,0,0,0]\n",
        "    recall = [0,0,0,0]\n",
        "    f1 = [0,0,0,0]\n",
        "    for i in range(4):\n",
        "        # precision = true positives/(true positives + false positives)\n",
        "        precision[i] = true_positives[i]/(true_positives[i] + false_positives[i])\n",
        "        # recall = true positives / (true positives + false negatives)\n",
        "        recall[i] = true_positives[i]/(true_positives[i] + false_negatives[i])\n",
        "        #f1 = 2 * precision * recall / (precision + recall)\n",
        "        f1[i] = 2 * precision[i] * recall[i]/ (precision[i] + recall[i])\n",
        "\n",
        "    average_f1 = sum(f1)/4\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\nAccuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}, Avg F1: {(100*average_f1):>0.1f}%,\\n TP: {true_positives},\\n TN: {true_negatives},\\n FP: {false_positives},\\n FN: {false_negatives}\")\n",
        "    return average_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "efca6ddd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efca6ddd",
        "outputId": "e9b1adf9-bad6-4ffb-f76f-4a39c73dbe0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0  loss is  1.3697469234466553\n",
            "Epoch:  1  loss is  1.3568542003631592\n",
            "Epoch:  2  loss is  1.3571736812591553\n",
            "Epoch:  3  loss is  1.3469232320785522\n",
            "Epoch:  4  loss is  1.3491284847259521\n",
            "Epoch:  5  loss is  1.325036883354187\n",
            "Epoch:  6  loss is  1.2987529039382935\n",
            "Epoch:  7  loss is  1.2874149084091187\n",
            "Epoch:  8  loss is  1.3009088039398193\n",
            "Epoch:  9  loss is  1.2808982133865356\n",
            "Epoch:  10  loss is  1.261202335357666\n",
            "Epoch:  11  loss is  1.2886735200881958\n",
            "Epoch:  12  loss is  1.1993000507354736\n",
            "Epoch:  13  loss is  1.0709288120269775\n",
            "Epoch:  14  loss is  0.9863799214363098\n",
            "Epoch:  15  loss is  1.3481875658035278\n",
            "Epoch:  16  loss is  1.1531018018722534\n",
            "Epoch:  17  loss is  1.1640846729278564\n",
            "Epoch:  18  loss is  1.0845599174499512\n",
            "Epoch:  19  loss is  1.0784456729888916\n",
            "Epoch:  20  loss is  0.880201518535614\n",
            "Epoch:  21  loss is  0.9238346219062805\n",
            "Epoch:  22  loss is  1.1229170560836792\n",
            "Epoch:  23  loss is  0.9090114831924438\n",
            "Epoch:  24  loss is  1.1364424228668213\n",
            "Epoch:  25  loss is  0.7604483366012573\n",
            "Epoch:  26  loss is  0.993959903717041\n",
            "Epoch:  27  loss is  0.9512768983840942\n",
            "Epoch:  28  loss is  0.8311287760734558\n",
            "Epoch:  29  loss is  1.0173012018203735\n",
            "Test Error: \n",
            "Accuracy: 56.6%, Avg loss: 0.061234, Avg F1: 52.5%,\n",
            " TP: [29, 231, 190, 329],\n",
            " TN: [996, 1003, 923, 609],\n",
            " FP: [56, 76, 97, 368],\n",
            " FN: [295, 66, 166, 70]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5245136747448642"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Step 5\n",
        "# Εκπαιδεύστε το νευρωνικό δίκτυο στο training set χρησιμοποιώντας τα εξής:\n",
        "#     optimizer: stochastic gradient descent\n",
        "#     learning rate: 0.002\n",
        "#     loss function: cross-entropy loss\n",
        "#     αριθμός εποχών: 30\n",
        "\n",
        "# set the device\n",
        "device = 'cpu'\n",
        "# create the model\n",
        "model = NeuralNetwork().to(device)\n",
        "# define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# define the learning rate\n",
        "learning_rate = 0.002\n",
        "# define the optimizer object\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "# define number of epochs\n",
        "num_epochs = 30\n",
        "train_neural_network(num_epochs, optimizer, train_dataloader, loss_fn, model, device)\n",
        "evaluate_neural_network(test_dataloader,model,loss_fn,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9b14cd11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b14cd11",
        "outputId": "f5a63d63-bf2d-495b-f6cd-aa0b925e3490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0  loss is  1.3480478525161743\n",
            "Epoch:  1  loss is  1.3751888275146484\n",
            "Epoch:  2  loss is  1.3303885459899902\n",
            "Epoch:  3  loss is  1.3466613292694092\n",
            "Epoch:  4  loss is  1.2311439514160156\n",
            "Epoch:  5  loss is  1.292157769203186\n",
            "Epoch:  6  loss is  1.2648189067840576\n",
            "Epoch:  7  loss is  1.240325927734375\n",
            "Epoch:  8  loss is  1.1554633378982544\n",
            "Epoch:  9  loss is  1.1667622327804565\n",
            "Epoch:  10  loss is  1.152687668800354\n",
            "Epoch:  11  loss is  1.3792901039123535\n",
            "Epoch:  12  loss is  1.2656704187393188\n",
            "Epoch:  13  loss is  1.1533973217010498\n",
            "Epoch:  14  loss is  1.2411187887191772\n",
            "Epoch:  15  loss is  1.0894440412521362\n",
            "Epoch:  16  loss is  1.0088576078414917\n",
            "Epoch:  17  loss is  0.8117411732673645\n",
            "Epoch:  18  loss is  0.9973186254501343\n",
            "Epoch:  19  loss is  1.2348523139953613\n",
            "Epoch:  20  loss is  1.0972038507461548\n",
            "Epoch:  21  loss is  1.175144910812378\n",
            "Epoch:  22  loss is  1.0216411352157593\n",
            "Epoch:  23  loss is  0.8774533271789551\n",
            "Epoch:  24  loss is  1.1752976179122925\n",
            "Epoch:  25  loss is  1.1418806314468384\n",
            "Epoch:  26  loss is  0.8813356757164001\n",
            "Epoch:  27  loss is  1.030590295791626\n",
            "Epoch:  28  loss is  1.1646555662155151\n",
            "Epoch:  29  loss is  1.029571771621704\n",
            "Test Error: \n",
            "Accuracy: 61.3%, Avg loss: 0.061171, Avg F1: 60.8%,\n",
            " TP: [108, 244, 240, 251],\n",
            " TN: [866, 991, 898, 840],\n",
            " FP: [186, 88, 122, 137],\n",
            " FN: [216, 53, 116, 148]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6079345523708465"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Step 6\n",
        "# set the device\n",
        "device = 'cuda'\n",
        "# create the model\n",
        "model = NeuralNetwork().to(device)\n",
        "# define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# define the learning rate\n",
        "learning_rate = 0.002\n",
        "# define the optimizer object\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "# define number of epochs\n",
        "num_epochs = 30\n",
        "train_neural_network(num_epochs, optimizer, train_dataloader, loss_fn, model, device)\n",
        "evaluate_neural_network(test_dataloader,model,loss_fn,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Όπως βλέπουμε, οι αποδόσεις ειναι παρόμοιες."
      ],
      "metadata": {
        "id": "DhVV-nQy-L9M"
      },
      "id": "DhVV-nQy-L9M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7\n",
        "# Αποθηκεύστε το μοντέλο που έχει την καλύτερη επίδοση στην μετρική f1 για το validation set\n",
        "# και χρησιμοποιήστε το για να μετρήσετε την απόδοση στο test set.\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_nn_validated(epochs, optimizer, train_dataloader, val_dataloader,cost_function, model, device):\n",
        "    max_f1, f1 = 0, 0\n",
        "    for epoch in range(epochs):\n",
        "        # for every batch\n",
        "        for X, y in train_dataloader:\n",
        "            # if using gpu dont forget to move the data there\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            # Compute prediction and loss\n",
        "            pred = model(X)\n",
        "            loss = cost_function(pred, y)\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # calculate the f1 using the validation set and save the max value along with the max weights (model)\n",
        "        f1 = 0\n",
        "        for val_X, val_y in val_dataloader:\n",
        "            val_X = val_X.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(val_X)\n",
        "                prediction = pred.argmax(1)  # Convert probabilities to class labels\n",
        "                f1 += f1_score(val_y, prediction, average='micro')\n",
        "\n",
        "        average_f1 = f1 / len(val_dataloader)\n",
        "        if average_f1 > max_f1:\n",
        "            max_f1 = average_f1\n",
        "            weights_opt = model.state_dict()\n",
        "\n",
        "        print(\"Epoch: \", epoch,\" loss is \", loss.item(), \"f1 is \", average_f1)\n",
        "\n",
        "    print(\"Max F1 is \", max_f1)\n",
        "    return weights_opt\n",
        "\n",
        "\n",
        "# set the device\n",
        "device = 'cpu'\n",
        "# create the model\n",
        "model = NeuralNetwork().to(device)\n",
        "# define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# define the learning rate\n",
        "learning_rate = 0.002\n",
        "# define the optimizer object\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "# define number of epochs\n",
        "num_epochs = 30\n",
        "# train and validate\n",
        "weights_opt = train_nn_validated(num_epochs, optimizer, train_dataloader, val_dataloader, loss_fn, model, device)\n",
        "model.load_state_dict(weights_opt)\n",
        "evaluate_neural_network(test_dataloader,model,loss_fn,device)"
      ],
      "metadata": {
        "id": "r0Kdc6UBNxpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b082344-621c-4278-cb56-3bb24db47e81"
      },
      "id": "r0Kdc6UBNxpy",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0  loss is  1.3770898580551147 f1 is  0.25125\n",
            "Epoch:  1  loss is  1.3498516082763672 f1 is  0.4075\n",
            "Epoch:  2  loss is  1.3480756282806396 f1 is  0.42625\n",
            "Epoch:  3  loss is  1.3491125106811523 f1 is  0.34375\n",
            "Epoch:  4  loss is  1.31696355342865 f1 is  0.33625\n",
            "Epoch:  5  loss is  1.365705132484436 f1 is  0.46\n",
            "Epoch:  6  loss is  1.3129147291183472 f1 is  0.4025\n",
            "Epoch:  7  loss is  1.3084797859191895 f1 is  0.57625\n",
            "Epoch:  8  loss is  1.2491220235824585 f1 is  0.45375\n",
            "Epoch:  9  loss is  1.2364510297775269 f1 is  0.51875\n",
            "Epoch:  10  loss is  1.279455304145813 f1 is  0.4175\n",
            "Epoch:  11  loss is  1.2415030002593994 f1 is  0.4375\n",
            "Epoch:  12  loss is  1.2073194980621338 f1 is  0.615\n",
            "Epoch:  13  loss is  1.2557036876678467 f1 is  0.545\n",
            "Epoch:  14  loss is  1.189634084701538 f1 is  0.60125\n",
            "Epoch:  15  loss is  1.2825883626937866 f1 is  0.56125\n",
            "Epoch:  16  loss is  1.0901494026184082 f1 is  0.57\n",
            "Epoch:  17  loss is  1.114262342453003 f1 is  0.63875\n",
            "Epoch:  18  loss is  1.2636183500289917 f1 is  0.64375\n",
            "Epoch:  19  loss is  0.922604501247406 f1 is  0.59375\n",
            "Epoch:  20  loss is  0.9614794850349426 f1 is  0.6325\n",
            "Epoch:  21  loss is  1.0404020547866821 f1 is  0.64625\n",
            "Epoch:  22  loss is  1.0170155763626099 f1 is  0.59625\n",
            "Epoch:  23  loss is  1.242422342300415 f1 is  0.6275\n",
            "Epoch:  24  loss is  0.8092858791351318 f1 is  0.6\n",
            "Epoch:  25  loss is  0.8853563666343689 f1 is  0.58625\n",
            "Epoch:  26  loss is  0.8292286992073059 f1 is  0.6375\n",
            "Epoch:  27  loss is  0.8519467115402222 f1 is  0.63875\n",
            "Epoch:  28  loss is  1.06269371509552 f1 is  0.60875\n",
            "Epoch:  29  loss is  1.1684070825576782 f1 is  0.65375\n",
            "Max F1 is  0.65375\n",
            "Test Error: \n",
            "Accuracy: 60.5%, Avg loss: 0.061663, Avg F1: 58.7%,\n",
            " TP: [87, 257, 205, 283],\n",
            " TN: [922, 944, 924, 794],\n",
            " FP: [130, 135, 96, 183],\n",
            " FN: [237, 40, 151, 116]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5865048230010461"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
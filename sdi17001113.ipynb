{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f294306",
   "metadata": {},
   "source": [
    "# <div style=\"text-align:center\">3η Εργασία</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5bb9a",
   "metadata": {},
   "source": [
    "Στην παρούσα εργασία θα ασχοληθείτε με την πρόβλεψη μουσικού είδους από σήματα\n",
    "μουσικής με τη χρήση νευρωνικών δικτύων. Πιο συγκεκριμένα, ο στόχος της εργασία είναι\n",
    "να ταξινομήσουμε 1 δευτερόλεπτο μουσικού σήματος στα εξής είδη: κλασσική μουσική, ποπ,\n",
    "ροκ, και μπλουζ. Για κάθε 1 δευτερόλεπτο σας παρέχονται δύο ειδών αναπαραστάσεις του\n",
    "ηχητικού σήματος: (i) MFCCs, και (ii) mel-spectograms. <br><br>\n",
    "Τα MFCCs είναι συντελεστές του φάσματος ισχύος μετασχηματισμένοι με βάση την κλίμακα\n",
    "mel, μία κλίμακα που είναι κοντά στον τρόπο που αντιλαμβάνεται ο άνθρωπος τα ηχητικά\n",
    "σήματα μέσω της ακοής. Στην δική μας περίπτωση χρησιμοποιούμε 13 συντελεστές οι οποίοι\n",
    "υπολογίζονται για κάθε 50 msec και επομένως για κάθε μουσικό κομμάτι του dataset\n",
    "προκύπτει μία ακολουθία από 20 feature vectors διάστασης 13. Για να αναπαραστήσουμε\n",
    "αυτή την πληροφορία μέσω ενός στατικού διανύσματος, το οποίο είναι ευκολότερο στην\n",
    "χρήση, υπολογίζουμε για κάθε έναν από τους 13 συντελεστές την μέση τιμή και την τυπική\n",
    "του απόκλιση από την ακολουθία των 20 χρονικών στιγμών. Καταλήγουμε λοιπόν με ένα\n",
    "διάνυσμα 26 χαρακτηριστικών για κάθε μουσικό κομμάτι του dataset. <br><br>\n",
    "To φασματογράφημα (spectrogram), που είναι ο δεύτερος τρόπος αναπαράστασης που θα\n",
    "χρησιμοποιήσουμε, είναι μία δισδιάστατη αναπαράσταση που δείχνει την χρονική εξέλιξη\n",
    "του φάσματος συχνοτήτων. Εάν στο spectrogram εφαρμόσουμε την κλίμακα mel, παίρνουμε\n",
    "το mel-spectrogram ή melgram με το οποίο και θα δουλέψουμε στην παρούσα εργασία.<br><br>\n",
    "Υπολογίζοντας και αντιστρέφοντας τους άξονες χρόνου και συχνότητας, προκύπτει για κάθε\n",
    "στοιχείο του συνόλου δεδομένων ένας πίνακας 21 (χρόνος) x 128 (συχνότητα).<br><br>\n",
    "Τα δεδομένα που θα χρησιμοποιήσετε βρίσκονται εδώ και είναι χωρισμένα στα σύνολα\n",
    "training (3200 δείγματα), validation (800 δείγματα) και test (1376 δείγματα) sets, τα οποία\n",
    "θα χρησιμοποιηθούν για εκπαίδευση, εύρεση υπερπαραμέτρων και αξιολόγηση της\n",
    "ικανότητας γενίκευσης αντίστοιχα.<br><br>\n",
    "Ακολουθήστε τις οδηγίες των παρακάτω ερωτημάτων και ετοιμάστε τις απαντήσεις σας\n",
    "τρέχοντας τον κώδικά σας στο Google Colab. Το framework που θα πρέπει να χρησιμοποιηθεί\n",
    "για τον προγραμματισμό των νευρωνικών είναι υποχρεωτικά το Pytorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e633762",
   "metadata": {},
   "source": [
    "### <div style=\"text-align:center\"> [Ερώτημα 1: Feedforward Neural Network] </div>\n",
    "*Βήμα 1: Φόρτωση δεδομένων (mfccs)* <br><br>\n",
    "Ξεκινάμε φορτώνοντας τα mfcc δεδομένα για train, validation και test μέσω των αντίστοιχων\n",
    "numpy αρχείων X.npy και labels.npy. Στην συνέχεια μετασχηματίζουμε τα labels από strings\n",
    "(classical, blues etc) σε ακέραιους αριθμούς από 0 μέχρι 3, κρατώντας το αντίστοιχο mapping\n",
    "από τα ονόματα των κλάσεων στους ακεραίους. Τέλος φορτώνουμε τα δεδομένα μας σε 3\n",
    "Pytorch dataloaders (ένα για κάθε σύνολο δεδομένων) με batch size 16, ώστε να μπορούν\n",
    "να χρησιμοποιηθούν στα μοντέλα μας. Δώστε επίσης το όρισμα shuffle=True στους train και\n",
    "validation dataloaders.<br><br>\n",
    "*Βήμα 2: Ορισμός Νευρωνικού Δικτύου*<br><br>\n",
    "Ορίστε μία κλάση πλήρως συνδεδεμένου Νευρωνικού Δικτύου (fully connected neural\n",
    "nework) το οποίο να αποτελείται από τα 4 επίπεδα με αριθμούς νευρώνων 26, 128, 32 και 4\n",
    "αντίστοιχα, όπου 26 είναι η διάσταση της εισόδου και 4 ο αριθμός των κλάσεων που θα\n",
    "προβλεφθούν.<br><br>\n",
    "*Βήμα 3: Ορισμός διαδικασίας εκπαίδευσης*<br><br>\n",
    "Ορίστε μία συνάρτηση που θα είναι αρμόδια για την εκπαίδευση του δικτύου. Συγκεκριμένα,\n",
    "δεδομένου ενός αριθμού εποχών, ενός optimizer, ενός dataloader, μιας συνάρτησης\n",
    "κόστους και ενός νευρωνικού θα περνάει κάθε batch από το νευρωνικό, θα υπολογίζει και\n",
    "θα τυπώνει το loss και θα ενημερώνει τα βάρη, ενώ θα τερματίζει επιστρέφοντας το\n",
    "νευρωνικό δίκτυο, όταν ο αριθμός των εποχών επιτευχθεί.<br><br>\n",
    "*Βήμα 4: Ορισμός διαδικασίας αξιολόγησης*<br><br>\n",
    "Ορίστε αντίστοιχα μία συνάρτηση αξιολόγησης, η οποία θα περνάει όλα τα batches ενός\n",
    "dataloader από το μοντέλο παίρνοντας τις προβλέψεις του και χωρίς να ενημερώνει τα βάρη.\n",
    "Μέσω των προβλέψεων θα υπολογίζει και θα επιστρέφει (i) το loss, (ii) τo f1 macro averaged,\n",
    "(iii) το accuracy, και (iv) confusion matrix.<br><br>\n",
    "*Βήμα 5: Εκπαίδευση δικτύου*<br><br>\n",
    "Εκπαιδεύστε το νευρωνικό δίκτυο στο training set χρησιμοποιώντας τα εξής:\n",
    "* optimizer: `stochastic gradient descent`\n",
    "* learning rate: `0.002`\n",
    "* loss function: `cross-entropy loss`\n",
    "* αριθμός εποχών: `30` \n",
    "\n",
    "Στην συνέχεια χρησιμοποιήστε την συνάρτηση αξιολόγησης του προηγούμενου ερωτήματος\n",
    "για να υπολογίσετε τις επιδόσεις του εκπαιδευμένου μοντέλου στο test set. Τι επιδόσεις\n",
    "πετυχαίνετε;<br><br>\n",
    "*Βήμα 6: Εκπαίδευση δικτύου με GPU*<br><br>\n",
    "Επαναλάβετε το βήμα 5, αλλά αυτή την φορά να έχετε αρχικά μεταφέρει τα δεδομένα και το\n",
    "αρχικοποιημένο νευρωνικό σας δίκτυο στην GPU του colab. Βεβαιωθείτε ότι η εκπαίδευση\n",
    "τρέχει στην GPU και τυπώστε τις διαφορές στους χρόνους εκτέλεσης σε GPU και CPU.\n",
    "Βεβαιωθείτε ότι το colab session σας περιλαμβάνει χρήση GPU - η οποία είναι δωρεάν.<br><br>\n",
    "*Βήμα 7: Επιλογή μοντέλου*<br><br>\n",
    "Κατά την διάρκεια εκπαίδευσης (30 εποχές) προκύπτουν διαφορετικά στιγμιότυπα του\n",
    "νευρωνικού μας, δηλαδή μοντέλα που έχουν διαφορετικά βάρη. Κατά την διαδικασία\n",
    "βελτιστοποίησης, δεν γνωρίζουμε ποιο στιγμιότυπο του μοντέλου μας έχει την καλύτερη\n",
    "δυνατότητα γενίκευσης. Για τον λόγο αυτό θα χρησιμοποιήσουμε το validation set στο τέλος\n",
    "κάθε εποχής ώστε να αξιολογούμε τα στιγμιότυπα του μοντέλου. Αποθηκεύστε το μοντέλο\n",
    "που έχει την καλύτερη επίδοση στην μετρική f1 για το validation set και χρησιμοποιήστε το\n",
    "για να μετρήσετε την απόδοση στο test set. Σχολιάστε τα αποτελέσματα.<br><br>\n",
    "Για τα επόμενα βήματα της εργασίας θα πρέπει να εργάζεστε με τον ίδιο τρόπο\n",
    "χρησιμοποιώντας το validation set για να βρείτε το κατάλληλο στιγμιότυπο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4602bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('/content/drive/MyDrive/Colab Notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bf3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Step 1\n",
    "#main_path = '/content/drive/MyDrive/Colab Notebooks/data/music_genre_data_di'\n",
    "main_path = 'data/music_genre_data_di'\n",
    "# Loading Training Data\n",
    "x_train = np.load(main_path + '/train/mfccs/X.npy')\n",
    "y_train = np.load(main_path + '/train/mfccs/labels.npy')\n",
    "# Loading Test Data\n",
    "x_test = np.load(main_path + '/test/mfccs/X.npy')\n",
    "y_test = np.load(main_path + '/test/mfccs/labels.npy')\n",
    "# Loading Validation Data\n",
    "x_val = np.load(main_path + '/val/mfccs/X.npy')\n",
    "y_val = np.load(main_path + '/val/mfccs/labels.npy')\n",
    "# Create the dictionary matching every genre to its index in the unique values of the train array\n",
    "unique_values = np.unique(y_train)\n",
    "replacement_dict = {value: i for i, value in enumerate(unique_values)}\n",
    "# Replace the values in each of the arrays with the values from the dictionary\n",
    "for i in range(len(unique_values)):\n",
    "    y_train = np.where(y_train == unique_values[i], replacement_dict[unique_values[i]], y_train)\n",
    "    y_test = np.where(y_test == unique_values[i], replacement_dict[unique_values[i]], y_test)\n",
    "    y_val = np.where(y_val == unique_values[i], replacement_dict[unique_values[i]], y_val)\n",
    "# Replace the ints encoded as strings to plain ints\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "# Create tensors from numpuarrays\n",
    "x_train = torch.from_numpy(x_train).float() # There was a type mismatch float64 instead of float32\n",
    "y_train = torch.from_numpy(y_train).long() # And another type mismatch for long instead of int\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "# Creating datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "# Load on dataloders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size=16, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81828a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Step 2\n",
    "# Ορίστε μία κλάση πλήρως συνδεδεμένου Νευρωνικού Δικτύου (fully connected neural nework) \n",
    "# το οποίο να αποτελείται από τα 4 επίπεδα με αριθμούς νευρώνων 26, 128, 32 και 4 αντίστοιχα, \n",
    "# όπου 26 είναι η διάσταση της εισόδου και 4 ο αριθμός των κλάσεων που θα προβλεφθούν.\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 26 --> 128 --> 32 --> 4\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(26, 128),  # 26 --> 128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),    # 128 --> 32\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4),     # 32 --> 4\n",
    "        )\n",
    "    # Every nn.Module subclass implements the operations on input data in the forward method.\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec190de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 \n",
    "# Ορίστε μία συνάρτηση που θα είναι αρμόδια για την εκπαίδευση του δικτύου. \n",
    "# Συγκεκριμένα, δεδομένου ενός αριθμού εποχών, ενός optimizer, ενός dataloader, \n",
    "# μιας συνάρτησης κόστους και ενός νευρωνικού θα περνάει κάθε batch από το νευρωνικό, \n",
    "# θα υπολογίζει και θα τυπώνει το loss και θα ενημερώνει τα βάρη, \n",
    "# ενώ θα τερματίζει επιστρέφοντας το νευρωνικό δίκτυο, όταν ο αριθμός των εποχών επιτευχθεί.\n",
    "def train_neural_network(epochs, optimizer, dataloader, cost_function, model, device):\n",
    "    for epoch in range(epochs):\n",
    "        # for every batch\n",
    "        for X, y in dataloader:\n",
    "            # if using gpu dont forget to move the data there\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = cost_function(pred, y)\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: \",epoch,\" loss is \",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "324eaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "# Ορίστε αντίστοιχα μία συνάρτηση αξιολόγησης, \n",
    "# η οποία θα περνάει όλα τα batches ενός dataloader από το μοντέλο παίρνοντας τις προβλέψεις του \n",
    "# και χωρίς να ενημερώνει τα βάρη. Μέσω των προβλέψεων θα υπολογίζει και θα επιστρέφει \n",
    "# (i) το loss, \n",
    "# (ii) τo f1 macro averaged, \n",
    "# (iii) το accuracy, και \n",
    "# (iv) confusion matrix.\n",
    "def evaluate_neural_network(dataloader,model,loss_function,device):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # I used my knowledge of the number of classes but maybe it should be a parameter of the function\n",
    "    true_positives = [0, 0, 0, 0]  \n",
    "    false_positives = [0, 0, 0, 0]\n",
    "    false_negatives = [0, 0, 0, 0]\n",
    "    true_negatives = [0, 0, 0, 0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            # confusion matrix calculation \n",
    "            predictions = pred.argmax(1)\n",
    "            for i in range(len(predictions)): # for every prediction\n",
    "                if predictions[i] == y[i]: # if the prediction is true \n",
    "                    true_positives[y[i]] += 1 # increment the true positives of this class\n",
    "                    for x in range(4): # and for every class\n",
    "                        if x != y[i]: # that it is not the predicted class\n",
    "                            true_negatives[x] += 1 # incremenet the true negatives\n",
    "                else: # else if the prediction was not correct\n",
    "                    false_positives[predictions[i]] += 1 # the increment the false positives for the predicted class\n",
    "                    false_negatives[y[i]] += 1 # increment the false negatives for the correct class\n",
    "                    for x in range(4): # and for every other class\n",
    "                        if x != y[i] and x != predictions[i]: # that is not one of the two other classes\n",
    "                            true_negatives[x] += 1 # incremenet the true negatives\n",
    "    \n",
    "    \n",
    "    precision = [0,0,0,0]\n",
    "    recall = [0,0,0,0]\n",
    "    f1 = [0,0,0,0]\n",
    "    for i in range(4):\n",
    "        # precision = true positives/(true positives + false positives)\n",
    "        precision[i] = true_positives[i]/(true_positives[i] + false_positives[i])\n",
    "        # recall = true positives / (true positives + false negatives)\n",
    "        recall[i] = true_positives[i]/(true_positives[i] + false_negatives[i])\n",
    "        #f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1[i] = 2 * precision[i] * recall[i]/ (precision[i] + recall[i])\n",
    "    \n",
    "    average_f1 = sum(f1)/4\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\nAccuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}, Avg F1: {(100*average_f1):>0.1f}%,\\n TP: {true_positives},\\n TN: {true_negatives},\\n FP: {false_positives},\\n FN: {false_negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "efca6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  loss is  1.3497265577316284\n",
      "Epoch:  1  loss is  1.3767210245132446\n",
      "Epoch:  2  loss is  1.4008511304855347\n",
      "Epoch:  3  loss is  1.3435508012771606\n",
      "Epoch:  4  loss is  1.345068097114563\n",
      "Epoch:  5  loss is  1.329516053199768\n",
      "Epoch:  6  loss is  1.29408597946167\n",
      "Epoch:  7  loss is  1.345898985862732\n",
      "Epoch:  8  loss is  1.350320816040039\n",
      "Epoch:  9  loss is  1.2782609462738037\n",
      "Epoch:  10  loss is  1.3228410482406616\n",
      "Epoch:  11  loss is  1.2413537502288818\n",
      "Epoch:  12  loss is  1.2996456623077393\n",
      "Epoch:  13  loss is  1.2878665924072266\n",
      "Epoch:  14  loss is  1.3009588718414307\n",
      "Epoch:  15  loss is  1.1301867961883545\n",
      "Epoch:  16  loss is  1.1842806339263916\n",
      "Epoch:  17  loss is  1.1543397903442383\n",
      "Epoch:  18  loss is  0.8896665573120117\n",
      "Epoch:  19  loss is  1.2015047073364258\n",
      "Epoch:  20  loss is  0.9733373522758484\n",
      "Epoch:  21  loss is  1.1443930864334106\n",
      "Epoch:  22  loss is  1.0231294631958008\n",
      "Epoch:  23  loss is  0.9521099328994751\n",
      "Epoch:  24  loss is  1.0505201816558838\n",
      "Epoch:  25  loss is  1.072646141052246\n",
      "Epoch:  26  loss is  1.2921550273895264\n",
      "Epoch:  27  loss is  0.8881796598434448\n",
      "Epoch:  28  loss is  1.2719863653182983\n",
      "Epoch:  29  loss is  0.7516248226165771\n",
      "Test Error: \n",
      "Accuracy: 61.5%, Avg loss: 0.064116, Avg F1: 58.5%,\n",
      " TP: [58, 243, 257, 288],\n",
      " TN: [968, 990, 868, 772],\n",
      " FP: [84, 89, 152, 205],\n",
      " FN: [266, 54, 99, 111]\n"
     ]
    }
   ],
   "source": [
    "# Step 5 \n",
    "# Εκπαιδεύστε το νευρωνικό δίκτυο στο training set χρησιμοποιώντας τα εξής:\n",
    "#     optimizer: stochastic gradient descent\n",
    "#     learning rate: 0.002\n",
    "#     loss function: cross-entropy loss\n",
    "#     αριθμός εποχών: 30\n",
    "\n",
    "# set the device\n",
    "device = 'cpu'\n",
    "# create the model\n",
    "model = NeuralNetwork().to(device)\n",
    "# define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# define the learning rate\n",
    "learning_rate = 0.002\n",
    "# define the optimizer object\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "# define number of epochs\n",
    "num_epochs = 30\n",
    "train_neural_network(num_epochs, optimizer, train_dataloader, loss_fn, model, device)\n",
    "evaluate_neural_network(test_dataloader,model,loss_fn,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b14cd11",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# create the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# define the loss function\u001b[39;00m\n\u001b[0;32m      7\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Step 6 \n",
    "# set the device\n",
    "device = 'cuda'\n",
    "# create the model\n",
    "model = NeuralNetwork().to(device)\n",
    "# define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# define the learning rate\n",
    "learning_rate = 0.002\n",
    "# define the optimizer object\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "# define number of epochs\n",
    "num_epochs = 30\n",
    "train_neural_network(num_epochs, optimizer, train_dataloader, loss_fn, model, device)\n",
    "evaluate_neural_network(test_dataloader,model,loss_fn,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

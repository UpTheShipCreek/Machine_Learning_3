{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f294306",
   "metadata": {},
   "source": [
    "# <div style=\"text-align:center\">3η Εργασία</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5bb9a",
   "metadata": {},
   "source": [
    "Στην παρούσα εργασία θα ασχοληθείτε με την πρόβλεψη μουσικού είδους από σήματα\n",
    "μουσικής με τη χρήση νευρωνικών δικτύων. Πιο συγκεκριμένα, ο στόχος της εργασία είναι\n",
    "να ταξινομήσουμε 1 δευτερόλεπτο μουσικού σήματος στα εξής είδη: κλασσική μουσική, ποπ,\n",
    "ροκ, και μπλουζ. Για κάθε 1 δευτερόλεπτο σας παρέχονται δύο ειδών αναπαραστάσεις του\n",
    "ηχητικού σήματος: (i) MFCCs, και (ii) mel-spectograms. <br><br>\n",
    "Τα MFCCs είναι συντελεστές του φάσματος ισχύος μετασχηματισμένοι με βάση την κλίμακα\n",
    "mel, μία κλίμακα που είναι κοντά στον τρόπο που αντιλαμβάνεται ο άνθρωπος τα ηχητικά\n",
    "σήματα μέσω της ακοής. Στην δική μας περίπτωση χρησιμοποιούμε 13 συντελεστές οι οποίοι\n",
    "υπολογίζονται για κάθε 50 msec και επομένως για κάθε μουσικό κομμάτι του dataset\n",
    "προκύπτει μία ακολουθία από 20 feature vectors διάστασης 13. Για να αναπαραστήσουμε\n",
    "αυτή την πληροφορία μέσω ενός στατικού διανύσματος, το οποίο είναι ευκολότερο στην\n",
    "χρήση, υπολογίζουμε για κάθε έναν από τους 13 συντελεστές την μέση τιμή και την τυπική\n",
    "του απόκλιση από την ακολουθία των 20 χρονικών στιγμών. Καταλήγουμε λοιπόν με ένα\n",
    "διάνυσμα 26 χαρακτηριστικών για κάθε μουσικό κομμάτι του dataset. <br><br>\n",
    "To φασματογράφημα (spectrogram), που είναι ο δεύτερος τρόπος αναπαράστασης που θα\n",
    "χρησιμοποιήσουμε, είναι μία δισδιάστατη αναπαράσταση που δείχνει την χρονική εξέλιξη\n",
    "του φάσματος συχνοτήτων. Εάν στο spectrogram εφαρμόσουμε την κλίμακα mel, παίρνουμε\n",
    "το mel-spectrogram ή melgram με το οποίο και θα δουλέψουμε στην παρούσα εργασία.<br><br>\n",
    "Υπολογίζοντας και αντιστρέφοντας τους άξονες χρόνου και συχνότητας, προκύπτει για κάθε\n",
    "στοιχείο του συνόλου δεδομένων ένας πίνακας 21 (χρόνος) x 128 (συχνότητα).<br><br>\n",
    "Τα δεδομένα που θα χρησιμοποιήσετε βρίσκονται εδώ και είναι χωρισμένα στα σύνολα\n",
    "training (3200 δείγματα), validation (800 δείγματα) και test (1376 δείγματα) sets, τα οποία\n",
    "θα χρησιμοποιηθούν για εκπαίδευση, εύρεση υπερπαραμέτρων και αξιολόγηση της\n",
    "ικανότητας γενίκευσης αντίστοιχα.<br><br>\n",
    "Ακολουθήστε τις οδηγίες των παρακάτω ερωτημάτων και ετοιμάστε τις απαντήσεις σας\n",
    "τρέχοντας τον κώδικά σας στο Google Colab. Το framework που θα πρέπει να χρησιμοποιηθεί\n",
    "για τον προγραμματισμό των νευρωνικών είναι υποχρεωτικά το Pytorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e633762",
   "metadata": {},
   "source": [
    "### <div style=\"text-align:center\"> [Ερώτημα 1: Feedforward Neural Network] </div>\n",
    "*Βήμα 1: Φόρτωση δεδομένων (mfccs)* <br><br>\n",
    "Ξεκινάμε φορτώνοντας τα mfcc δεδομένα για train, validation και test μέσω των αντίστοιχων\n",
    "numpy αρχείων X.npy και labels.npy. Στην συνέχεια μετασχηματίζουμε τα labels από strings\n",
    "(classical, blues etc) σε ακέραιους αριθμούς από 0 μέχρι 3, κρατώντας το αντίστοιχο mapping\n",
    "από τα ονόματα των κλάσεων στους ακεραίους. Τέλος φορτώνουμε τα δεδομένα μας σε 3\n",
    "Pytorch dataloaders (ένα για κάθε σύνολο δεδομένων) με batch size 16, ώστε να μπορούν\n",
    "να χρησιμοποιηθούν στα μοντέλα μας. Δώστε επίσης το όρισμα shuffle=True στους train και\n",
    "validation dataloaders.<br><br>\n",
    "*Βήμα 2: Ορισμός Νευρωνικού Δικτύου*<br><br>\n",
    "Ορίστε μία κλάση πλήρως συνδεδεμένου Νευρωνικού Δικτύου (fully connected neural\n",
    "nework) το οποίο να αποτελείται από τα 4 επίπεδα με αριθμούς νευρώνων 26, 128, 32 και 4\n",
    "αντίστοιχα, όπου 26 είναι η διάσταση της εισόδου και 4 ο αριθμός των κλάσεων που θα\n",
    "προβλεφθούν.<br><br>\n",
    "*Βήμα 3: Ορισμός διαδικασίας εκπαίδευσης*<br><br>\n",
    "Ορίστε μία συνάρτηση που θα είναι αρμόδια για την εκπαίδευση του δικτύου. Συγκεκριμένα,\n",
    "δεδομένου ενός αριθμού εποχών, ενός optimizer, ενός dataloader, μιας συνάρτησης\n",
    "κόστους και ενός νευρωνικού θα περνάει κάθε batch από το νευρωνικό, θα υπολογίζει και\n",
    "θα τυπώνει το loss και θα ενημερώνει τα βάρη, ενώ θα τερματίζει επιστρέφοντας το\n",
    "νευρωνικό δίκτυο, όταν ο αριθμός των εποχών επιτευχθεί.<br><br>\n",
    "*Βήμα 4: Ορισμός διαδικασίας αξιολόγησης*<br><br>\n",
    "Ορίστε αντίστοιχα μία συνάρτηση αξιολόγησης, η οποία θα περνάει όλα τα batches ενός\n",
    "dataloader από το μοντέλο παίρνοντας τις προβλέψεις του και χωρίς να ενημερώνει τα βάρη.\n",
    "Μέσω των προβλέψεων θα υπολογίζει και θα επιστρέφει (i) το loss, (ii) τo f1 macro averaged,\n",
    "(iii) το accuracy, και (iv) confusion matrix.<br><br>\n",
    "*Βήμα 5: Εκπαίδευση δικτύου*<br><br>\n",
    "Εκπαιδεύστε το νευρωνικό δίκτυο στο training set χρησιμοποιώντας τα εξής:\n",
    "* optimizer: `stochastic gradient descent`\n",
    "* learning rate: `0.002`\n",
    "* loss function: `cross-entropy loss`\n",
    "* αριθμός εποχών: `30` \n",
    "\n",
    "Στην συνέχεια χρησιμοποιήστε την συνάρτηση αξιολόγησης του προηγούμενου ερωτήματος\n",
    "για να υπολογίσετε τις επιδόσεις του εκπαιδευμένου μοντέλου στο test set. Τι επιδόσεις\n",
    "πετυχαίνετε;\n",
    "*Βήμα 6: Εκπαίδευση δικτύου με GPU*<br><br>\n",
    "Επαναλάβετε το βήμα 5, αλλά αυτή την φορά να έχετε αρχικά μεταφέρει τα δεδομένα και το\n",
    "αρχικοποιημένο νευρωνικό σας δίκτυο στην GPU του colab. Βεβαιωθείτε ότι η εκπαίδευση\n",
    "τρέχει στην GPU και τυπώστε τις διαφορές στους χρόνους εκτέλεσης σε GPU και CPU.\n",
    "Βεβαιωθείτε ότι το colab session σας περιλαμβάνει χρήση GPU - η οποία είναι δωρεάν.<br><br>\n",
    "*Βήμα 7: Επιλογή μοντέλου*<br><br>\n",
    "Κατά την διάρκεια εκπαίδευσης (30 εποχές) προκύπτουν διαφορετικά στιγμιότυπα του\n",
    "νευρωνικού μας, δηλαδή μοντέλα που έχουν διαφορετικά βάρη. Κατά την διαδικασία\n",
    "βελτιστοποίησης, δεν γνωρίζουμε ποιο στιγμιότυπο του μοντέλου μας έχει την καλύτερη\n",
    "δυνατότητα γενίκευσης. Για τον λόγο αυτό θα χρησιμοποιήσουμε το validation set στο τέλος\n",
    "κάθε εποχής ώστε να αξιολογούμε τα στιγμιότυπα του μοντέλου. Αποθηκεύστε το μοντέλο\n",
    "που έχει την καλύτερη επίδοση στην μετρική f1 για το validation set και χρησιμοποιήστε το\n",
    "για να μετρήσετε την απόδοση στο test set. Σχολιάστε τα αποτελέσματα.<br><br>\n",
    "Για τα επόμενα βήματα της εργασίας θα πρέπει να εργάζεστε με τον ίδιο τρόπο\n",
    "χρησιμοποιώντας το validation set για να βρείτε το κατάλληλο στιγμιότυπο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bf3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Step 1\n",
    "main_path = 'data/music_genre_data_di'\n",
    "# Loading Training Data\n",
    "x_train = np.load(main_path + '/train/mfccs/X.npy')\n",
    "y_train = np.load(main_path + '/train/mfccs/labels.npy')\n",
    "# Loading Test Data\n",
    "x_test = np.load(main_path + '/test/mfccs/X.npy')\n",
    "y_test = np.load(main_path + '/test/mfccs/labels.npy')\n",
    "# Loading Validation Data\n",
    "x_val = np.load(main_path + '/val/mfccs/X.npy')\n",
    "y_val = np.load(main_path + '/val/mfccs/labels.npy')\n",
    "# Create the dictionary matching every genre to its index in the unique values of the train array\n",
    "unique_values = np.unique(y_train)\n",
    "replacement_dict = {value: i for i, value in enumerate(unique_values)}\n",
    "# Replace the values in each of the arrays with the values from the dictionary\n",
    "for i in range(len(unique_values)):\n",
    "    y_train = np.where(y_train == unique_values[i], replacement_dict[unique_values[i]], y_train)\n",
    "    y_test = np.where(y_test == unique_values[i], replacement_dict[unique_values[i]], y_test)\n",
    "    y_val = np.where(y_val == unique_values[i], replacement_dict[unique_values[i]], y_val)\n",
    "# Replace the ints encoded as strings to plain ints\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "# Create tensors from numpuarrays\n",
    "x_train = torch.from_numpy(x_train).float() # There was a type mismatch float64 instead of float32\n",
    "y_train = torch.from_numpy(y_train).long() # And another type mismatch for long instead of int\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "# Creating datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "# Load on dataloders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size=16, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81828a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Step 2\n",
    "# Ορίστε μία κλάση πλήρως συνδεδεμένου Νευρωνικού Δικτύου (fully connected neural nework) \n",
    "# το οποίο να αποτελείται από τα 4 επίπεδα με αριθμούς νευρώνων 26, 128, 32 και 4 αντίστοιχα, \n",
    "# όπου 26 είναι η διάσταση της εισόδου και 4 ο αριθμός των κλάσεων που θα προβλεφθούν.\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 26 --> 128 --> 32 --> 4\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(26, 128),  # 26 --> 128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),    # 128 --> 32\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4),     # 32 --> 4\n",
    "        )\n",
    "    # Every nn.Module subclass implements the operations on input data in the forward method.\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec190de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 \n",
    "# Ορίστε μία συνάρτηση που θα είναι αρμόδια για την εκπαίδευση του δικτύου. \n",
    "# Συγκεκριμένα, δεδομένου ενός αριθμού εποχών, ενός optimizer, ενός dataloader, \n",
    "# μιας συνάρτησης κόστους και ενός νευρωνικού θα περνάει κάθε batch από το νευρωνικό, \n",
    "# θα υπολογίζει και θα τυπώνει το loss και θα ενημερώνει τα βάρη, \n",
    "# ενώ θα τερματίζει επιστρέφοντας το νευρωνικό δίκτυο, όταν ο αριθμός των εποχών επιτευχθεί.\n",
    "def train_neural_network(epochs, optimizer, dataloader, cost_function, model, device):\n",
    "    for epoch in range(epochs):\n",
    "        # for every batch\n",
    "        for X, y in dataloader:\n",
    "            # if using gpu dont forget to move the data there\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = cost_function(pred, y)\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: \",epoch,\" loss is \",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "324eaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "recall = tf.keras.metrics.Recall()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "\n",
    "# Step 4\n",
    "# Ορίστε αντίστοιχα μία συνάρτηση αξιολόγησης, \n",
    "# η οποία θα περνάει όλα τα batches ενός dataloader από το μοντέλο παίρνοντας τις προβλέψεις του \n",
    "# και χωρίς να ενημερώνει τα βάρη. Μέσω των προβλέψεων θα υπολογίζει και θα επιστρέφει \n",
    "# (i) το loss, \n",
    "# (ii) τo f1 macro averaged, \n",
    "# (iii) το accuracy, και \n",
    "# (iv) confusion matrix.\n",
    "def evaluate_neural_network(dataloader,model,loss_function,device):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct, recall_val, precision_val = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            precision.update_state(y, pred.argmax(1))\n",
    "            precision_val += precision.result()\n",
    "            \n",
    "            recall.update_state(y, pred.argmax(1))\n",
    "            recall_val += recall.result()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    #precision_val /= size    \n",
    "    #recall_val /= size\n",
    "    f1_score = 2 * (precision_val * recall_val) / (precision_val + recall_val)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}, Avg F1: {(100*f1_score/len(dataloader)):>0.1f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efca6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  loss is  1.3862247467041016\n",
      "Epoch:  1  loss is  1.4020320177078247\n",
      "Epoch:  2  loss is  1.3719379901885986\n",
      "Epoch:  3  loss is  1.3561828136444092\n",
      "Epoch:  4  loss is  1.3456300497055054\n",
      "Epoch:  5  loss is  1.3699263334274292\n",
      "Epoch:  6  loss is  1.3300626277923584\n",
      "Epoch:  7  loss is  1.3684959411621094\n",
      "Epoch:  8  loss is  1.3115935325622559\n",
      "Epoch:  9  loss is  1.295924186706543\n",
      "Epoch:  10  loss is  1.3068081140518188\n",
      "Epoch:  11  loss is  1.290177345275879\n",
      "Epoch:  12  loss is  1.2803939580917358\n",
      "Epoch:  13  loss is  1.3165194988250732\n",
      "Epoch:  14  loss is  1.2528231143951416\n",
      "Epoch:  15  loss is  1.2272459268569946\n",
      "Epoch:  16  loss is  1.2244884967803955\n",
      "Epoch:  17  loss is  1.217801809310913\n",
      "Epoch:  18  loss is  1.1765406131744385\n",
      "Epoch:  19  loss is  1.1338448524475098\n",
      "Epoch:  20  loss is  1.0468138456344604\n",
      "Epoch:  21  loss is  1.025740623474121\n",
      "Epoch:  22  loss is  1.0789377689361572\n",
      "Epoch:  23  loss is  1.1226600408554077\n",
      "Epoch:  24  loss is  0.9506574273109436\n",
      "Epoch:  25  loss is  1.09593665599823\n",
      "Epoch:  26  loss is  1.0545214414596558\n",
      "Epoch:  27  loss is  0.954001784324646\n",
      "Epoch:  28  loss is  0.8546969294548035\n",
      "Epoch:  29  loss is  0.7622132301330566\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.064566, Avg F1: 56.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5 \n",
    "# Εκπαιδεύστε το νευρωνικό δίκτυο στο training set χρησιμοποιώντας τα εξής:\n",
    "#     optimizer: stochastic gradient descent\n",
    "#     learning rate: 0.002\n",
    "#     loss function: cross-entropy loss\n",
    "#     αριθμός εποχών: 30\n",
    "\n",
    "# set the device\n",
    "device = 'cpu'\n",
    "# create the model\n",
    "model = NeuralNetwork().to(device)\n",
    "# define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# define the learning rate\n",
    "learning_rate = 0.002\n",
    "# define the optimizer object\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "# define number of epochs\n",
    "num_epochs = 30\n",
    "train_neural_network(num_epochs, optimizer, train_dataloader, loss_fn, model, device)\n",
    "evaluate_neural_network(test_dataloader,model,loss_fn,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
